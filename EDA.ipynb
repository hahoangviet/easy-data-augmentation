{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af609975",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk import pos_tag, word_tokenize\n",
    "from nltk.corpus import wordnet as wn\n",
    "import spacy\n",
    "from spacy.lang.fr.examples import sentences\n",
    "from spacy.lang.en.examples import sentences\n",
    "from spacy.lang.fr.stop_words import STOP_WORDS as fr_stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98419c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('questions_fr_train.csv')\n",
    "fr = spacy.load(\"fr_core_news_md\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ba72dd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tokens_lemmas(sentence):\n",
    "    sen = fr(sentence)\n",
    "    lemmas = []\n",
    "    tokens = []\n",
    "    for token in sen:\n",
    "        lemmas.append(token.lemma_)\n",
    "        tokens.append(token.text) \n",
    "    return tokens, lemmas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "98e52b52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_synonyms(word):\n",
    "    syns=[synset.lemma_names('fra') for synset in wn.synsets(word, lang='fra')]\n",
    "    ss = set()\n",
    "    for s in syns:\n",
    "        for syn in s:\n",
    "            ss.add(syn)\n",
    "    if word in ss:\n",
    "        ss.remove(word)\n",
    "    return list(ss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "121dc71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def synonym_replacement(sentence, alpha):\n",
    "    tokens, lemmas = get_tokens_lemmas(sentence)\n",
    "    tokens_copy = tokens.copy()\n",
    "    n = round(alpha*len(lemmas))\n",
    "    k = 0\n",
    "    candidates = []\n",
    "    while(k < n):\n",
    "        j = random.randint(0, len(lemmas)-1)\n",
    "        if lemmas[j].lower() not in fr_stop:\n",
    "            candidates.append(j)\n",
    "            k += 1\n",
    "    idx = set(candidates)\n",
    "    for i in idx:\n",
    "        synset = get_synonyms(lemmas[i].lower())\n",
    "        if synset != []:\n",
    "            j = random.randint(0, len(synset)-1)\n",
    "            syn = synset[j]\n",
    "            tokens[i] = syn\n",
    "    if tokens == tokens_copy:\n",
    "        return sentence\n",
    "    else:\n",
    "        return ' '.join(e for e in tokens).replace(' -', '-').replace('\\' ', '\\'').replace(' )', ')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f206af5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_insertion(sentence, alpha):\n",
    "    tokens, lemmas = get_tokens_lemmas(sentence)\n",
    "    tokens_copy = tokens.copy()\n",
    "    n = round(alpha*len(lemmas))\n",
    "    candidates = []\n",
    "    for i in range(len(lemmas)):\n",
    "        if lemmas[i].lower() not in fr_stop:\n",
    "            candidates.append(i)\n",
    "    for i in range(n):\n",
    "        j = random.choice(candidates)\n",
    "        synset = get_synonyms(lemmas[j].lower())\n",
    "        if synset != []:\n",
    "            k = random.randint(0, len(synset)-1)\n",
    "            syn = synset[k]\n",
    "            pos = random.randint(0, len(tokens))\n",
    "            tokens.insert(pos, syn)\n",
    "    if tokens == tokens_copy:\n",
    "        return sentence\n",
    "    else:\n",
    "        return ' '.join(e for e in tokens).replace(' -', '-').replace('\\' ', '\\'').replace(' )', ')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a295c29e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_swap(sentence, alpha):\n",
    "    wt = word_tokenize(sentence)\n",
    "    n = round(alpha*len(wt))\n",
    "    for i in range(n):\n",
    "        w1 = wt.index(random.choice(wt))\n",
    "        w2 = wt.index(random.choice(wt))\n",
    "        wt[w1], wt[w2] = wt[w2], wt[w1]\n",
    "    return ' '.join(e for e in wt).replace(' -', '-').replace('\\' ', '\\'').replace(' )', ')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "46fab1c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_deletion(sentence, alpha):\n",
    "    wt = word_tokenize(sentence)\n",
    "    candidates = []\n",
    "    for i in range(len(wt)):\n",
    "        if random.random() > alpha:\n",
    "            candidates.append(wt[i])\n",
    "    return ' '.join(e for e in candidates).replace(' -', '-').replace('\\' ', '\\'').replace(' )', ')')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d0f06e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_augmentation(data, alpha, operation):\n",
    "    n = len(data)\n",
    "    data_copy = data.copy()\n",
    "    for i in range(n):\n",
    "        if operation.lower() == 'sr':\n",
    "            data_copy.at[i, 'question'] = synonym_replacement(data.at[i, 'question'], alpha)\n",
    "        if operation.lower() == 'ri':\n",
    "            data_copy.at[i, 'question'] = random_insertion(data.at[i, 'question'], alpha)\n",
    "        if operation.lower() == 'rs':\n",
    "            data_copy.at[i, 'question'] = random_swap(data.at[i, 'question'], alpha)\n",
    "        if operation.lower() == 'rd':\n",
    "            data_copy.at[i, 'question'] = random_deletion(data.at[i, 'question'], alpha)\n",
    "    return data_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f628026d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augment_data(data, k, alpha, operation):\n",
    "    data_copy = data.copy()\n",
    "    for i in range(k):\n",
    "        df = create_augmentation(data, alpha, operation)\n",
    "        data_copy = pd.concat([data_copy, df], ignore_index = True)\n",
    "    return data_copy.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91183a24",
   "metadata": {},
   "outputs": [],
   "source": [
    "# augment the data 2 times using synonym replacement operations\n",
    "sr = augment_data(df, 2, 0.2, 'sr')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0dca0820",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Je suis travailleur salarié(e). Puis-je refuser de faire des heures supplémentaires ou de travailler de nuit ?',\n",
       "       'Je suis travailleur salarié(e) . Puis-je refuser de faire des moment autre ou de travailler de soir ?',\n",
       "       'Je suis travailleur salarié(e) . Puis-je refuser de ouvrir des heures autre ou de travailler de nuit ?'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# original data and sentences after synonym replacement\n",
    "sr[sr['id'] == 1102]['question'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5cb275b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
